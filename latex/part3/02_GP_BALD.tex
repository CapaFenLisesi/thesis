%!TEX root = ../thesis.tex

% defining plot colors
\definecolor{mycolor1}{rgb}{0.8,0.8,0}
\definecolor{mycolor2}{rgb}{0,1,1}
\definecolor{mycolor3}{rgb}{1,0,1}
\definecolor{mycolor4}{rgb}{1,0.8,0.5}
\definecolor{mycolor5}{rgb}{0.7,0.4,0.80}

\begin{summarycontributions}
The work presented in this chapter has been carried out in collaboration with Neil M.\ T.\ Houlsby, Jose Miguel Hernandez-Lobato, Zoubin Ghahramani and M\'{a}t\'{e} Lengyel. This work forms the basis of the technical report \citep{Houlsby2011} and the peer-reviewed conference paper \citep{Houlsby2012preference}. In addition, elements of this work have also been presented by FH and NMTH at the NIPS 2011 workshops ``Preference Learning'' and ``Bayesian Optimization and Active Learning''. All authors contributed equally to the design of the research and to the development of statistical models. The derivation of the preference kernel in Section \eqref{sec:prefKernel} and the approximation to the BALD formula in Eqn.\ \eqref{eqn:BALD_GPC} are original contributions by FH. Experiments were mainly implemented and carried out by NMTH. Figures \ref{fig:artificial} and \ref{fig:BALD_GPC_results} are taken from \citep{Houlsby2011}, as published or with slight modification, with the co-authors' consent.
\end{summarycontributions}

\section{Introduction}

In the previous chapter I introduced a general framework for Bayesian active learning based on scoring rules. On one hand, the framework is very satisfying in that it highlights the connections between various techniques and optimisation problems that have cropped up in the machine learning literature. On the other hand, the information quantities the framework is built on are intractable to calculate and optimise, and the framework provides no practical guidance as to how the quantities can be effectively calculated in practical active learning applications.

In this section I focus on the special case of Bayesian active learning using the Shannon's mutual information (see Section \ref{sec:active_learning_shannon_information}). I present a practical method that makes active learning possible even in complicated Bayesian models by exploiting the symmetry of Shannon's information (Eqn \eqref{eqn:mutualinfo_as_KLdivergence}). The method bears resemblance to the principle of maximal disagreement introduced by \citet{seung1992}, hence we call the method Bayesian Active Learning by Disagreement (BALD).

In the second half of the chapter I derive a Bayesian active learning algorithm for binary classification based on the Gaussian process classification model \citep[Chapter 3]{Rasmussen2006}. I will also discuss how this simple model can be extended and applied to binary preference learning and multi-user preference elicitation problems. Experimental results presented in this chapter demonstrate that BALD is a very competitive method for active classification and that it often provides best-in-class performance compared to other myopic active learning methods.

\section{Bayesian active learning by disagreement}

Recall the objective function for information theoretic active learning, first proposed by \citet{lindley1956}, is to seek a data point $\x$ that satisfies:

\begin{align}	
	\label{eqn:ent_change}
	\argmax_{\x} \genentropy{}{\param | \data} - \expect{\y\sim p(\y|\x\data)} \left[ \genentropy{}{\param| \y, \x,\data} \right] 
\end{align}

Recall from Chapter \ref{sec:active_learning_framework} that expectation over the unseen output $\y$ is required because this will not be revealed until the selection of the next input $\x$ is made.

Computationally, Eqn.\ \eqref{eqn:ent_change} poses two difficulties: Firstly, to consider $k$ different potential queries $\x$, when the output $\y$ may take on $l$ possible values, one has to apply Bayes' rule and update the posterior $k\cdot l$ times to evaluate the objective for each $\x$--$\y$ pair in question. Because updating the posterior is often the computationally most intensive part of Bayesian active learning, performing this step multiple times can be prohibitive.

Secondly, calculating entropies in parameter space may be hard, or intractable. Often we can only approximate the posterior via samples, from which estimating entropy is notoriously difficult \citep{panzeri2007}. Worse still, for non-parametric processes the parameter space has infinite dimensions so Eqn.\ \eqref{eqn:ent_change} becomes poorly defined and non-trivial to compute. \citep{MacKay1992, Krishnapuram2004, Lawrence2004} must therefore make approximations to the complicated entropy term.

If we use the logarithmic score to define the entropy in Eqn.\ \eqref{eqn:ent_change} both of these problems can be overcome. As discussed in Chapter \ref{sec:scoring_rules}, Shannon's mutual information, unlike value of information in general, is symmetric. The information variable $X$ provides about $Y$ is the same as the information $Y$ provides about $X$. In this chapter, following \citep{ExactInformation} we expoloit this unique symmetry property and rearrange Eqn.\ \eqref{eqn:ent_change} in a form that expresses $\information{\theta}{\y}{\data;\x}$ in terms of entropies in the output space $\Ye$:

\begin{align}
	&\argmax_{\x} H[\param | \data] - \expect{\y\sim p(\y|\x\data)} \left[ H[\param| \y, \x,\data] \right] = \tag{\ref{eqn:ent_change}}\\
	&\argmax_{\x} \conditionalinformation{\mbox{Shannon}}{\theta}{\y}{\data;\x} =\\
	&\argmax_{\x} \conditionalinformation{\mbox{Shannon}}{\y}{\param}{\data;\x} =\\
	&\argmax_{\x} H[\y \vert \x, \data] - \expect{\param\sim p(\param|\data)} \left[ H[\y \vert \x,\param] \right] \label{eqn:rearrangement} 
\end{align}

Eqn.\ \eqref{eqn:rearrangement} overcomes the aforementioned challenges. Entropies are now calculated in the -- usually low dimensional -- output space. Also $\param$ is now conditioned only on $\data$, never on $\x$ and $\y$, so we do not need to update the posterior for every possible outcome, saving a factor of $k\cdot l$ posterior updates.

Equation \eqref{eqn:rearrangement} provides us with an intuition about the objective; we seek the $\x$ for which the model is marginally most uncertain about $\y$ (high $H[\y \vert \x, \data]$), but for which individual setting of the parameters are confident (low $\expect{\param\sim p(\param|\data)} \left[ H[\y \vert \x,\param] \right]$). This can be interpreted as seeking the $\x$ for which the parameters under the posterior disagree about the outcome the most. Indeed, the objective function can further be written as:

\begin{align}
	&\argmax_{\x} H[\y \vert \x, \data] - \expect{\param\sim p(\param|\data)} \left[ H[\y \vert \x,\param] \right] = \tag{\ref{eqn:rearrangement}}\\
	&\argmax_{\x} \expect{\param\sim p(\param|\data)}  \divergence{KL}{p(\y\vert\param;\x)}{p(\y\vert\data;\x)}
\end{align}

So by maximising the expected reduction in posterior entropy the learner seeks a measurement such that each probable parameter $\theta$ predicts something different for what the outcome $\y$ will be. In the statistics literature this is known as the \emph{principle of maximal disagreement} and provides the theoretical motivation for \emph{query by committee} methods \citep{Freund1997}. We will call the approach of using the rearranged objective in Eqn.\ \eqref{eqn:rearrangement} as Bayesian Active Learning by Disagreement or BALD \citep{Houlsby2011,Houlsby2012preference,Huszar2012quantum}. Note that these rearrangements were only possible because of the symmetry of Shannon's mutual information, hence this interpretation does not hold in general for Bayesian active learning when using a scoring rule other than the logarithmic one.

\section{Related techniques}

In this section I briefly review some of several related algorithms that are applicable to active learning and relate them to the BALD information theoretic objective \eqref{eqn:rearrangement}.

Other work that uses rearrangement to observation space (Eqn.\ \eqref{eqn:rearrangement}) include Maximum Entropy Sampling (MES) \citep{sebastiani2000}. MES was proposed for regression models with input-independent observation noise. The MES objective function is similar to Eqn.\ \eqref{eqn:rearrangement} but with its second term ignored. This is theoretically well motivated if the output noise is indeed independent of the input, that is when $H[\y\vert\param,\x]$ is constant in $x$.

For heteroscedastic regression or other applications such as classification, this assumption is violated, thus MES is inappropriate; it fails to differentiate between model uncertainty and observation uncertainty (about which our model may be confident). Many toy demonstrations show the `information based' active learning criterion behaving pathologically in classification by repeatedly querying points close the decision boundary or in regions of high observation uncertainty, \eg those presented in \citep{dasgupta2008, huang2010}. This is because MES is inappropriate in those circumstances. Using the full BALD objective from Eqn.\ \eqref{eqn:rearrangement} distinguishes between observation and model uncertainty and eliminates these problems.

The Informative Vector Machine \citep[IVM,][]{Lawrence2004} algorithm was designed for sub-sampling a data set to be used to train a Gaussian process regression or classification model. It may not fall under the term `active learning' because all $\y$ values are revealed to the algorithm a priori. Their objective is based on Shannon's entropy as in Eqn.\ \eqref{eqn:ent_change}, however the algorithm is not based on a rearrangement to data space (Eqn.\ \eqref{eqn:rearrangement}). Posterior entropy calculations are made approximately on the $n$ dimensional subspace corresponding to the $n$ observed data points using the Gaussian process covariance matrix. To chose among a pool of $k$ possible points, $k$ posterior updates are required in each step. \citep{Lawrence2004} proposes a quick method based on Assumed Density Filtering to perform these updates quickly. The IVM essentially optimises the same objective function, but makes different trade-offs and approximations. As we will see, BALD often performs better in practical situations.

Certain non-probabilistic methods have close analogues to information theoretic active learning. Perhaps the most ubiquitous is active learning for support vector machines \citep[SVM,][]{Tong2002,seung1992} where the volume of the version space is used as an objective function. This objective function is in fact closely related to Bayesian active learning. If a uniform (improper) prior is used with a deterministic classification likelihood it can be shown that the logarithmic volume of the version space and Bayesian posterior entropy are equivalent \citep{Seung1992}.

However, just as Bayesian posteriors become intractable after observing many data points, version space too can become very complicated and its volume intractable to compute. \citep{Tong2002} proposes approximating version space with a simple shape, such as a hyper-sphere. This closely resembles approximating a Bayesian posterior using a Gaussian distribution via the Laplace or EP approximations. \citep{seung1992} sidesteps the problem by working in the space of observations, much like BALD does. The algorithm, Query by Committee (QBC), samples parameters from version space (committee members), which vote on the outcome of each possible measurement $\x$ in question. The $\x$ with the most balanced vote is selected; this is termed the `principle of maximal disagreement'. If BALD is used in conjunction with a Monte Carlo approximation to the posterior, the resulting algorithm is very similar to query-by-committee, but with a theoretically sound, probabilistic measure of disagreement. QBC's deterministic vote criterion discards confidence in the predictions and so can exhibit similar pathologies as MES.

%  ######   ########  
% ##    ##  ##     ## 
% ##        ##     ## 
% ##   #### ########  
% ##    ##  ##        
% ##    ##  ##        
%  ######   ##        

\section{BALD for Gaussian Process classification}

BALD exploits the fact that in many active learning applications the output space $\Ye$ is often simpler than the parameter space $\Theta$. Here I consider the problem of active learning for binary classification, when the output takes one of two possible values $y \in \{-1,1\}$. Given the simplicity of the outputs, binary classification is a highly relevant use-case for BALD.

I will use a non-parametric Bayesian classification model, Gaussian process classification \citep[GPC,][]{Rasmussen2006} to demonstrate the usefulness of BALD. GPC appears to be an especially challenging problem for information-theoretic active learning because its parameter space is infinite. Therefore, computing entropy of the posterior is non-trivial. However, by using the BALD approach and Eqn.\ \eqref{eqn:rearrangement} we are able to fully calculate the relevant information quantities without having to work out entropies for infinite dimensional objects. 


The probabilistic model underlying GPC is as follows:

\begin{align}
	f \sim \mathrm{GP}(\mu(\cdot),k(\cdot,\cdot)) \qquad \y\vert\x,f \sim\mathrm{Bernoulli}(\Phi(f(\x))) \label{eqn:GPC_model}
\end{align}

The latent parameter, now called $f$ (previously denoted as $\param$), is a real-valued function $\mathcal{X}\rightarrow\mathbb{R}$, and is assigned a Gaussian process prior with mean $\mu(\cdot)$ and covariance function $k(\cdot,\cdot)$.

We consider the probit case where, given the value of $f$, the binary label $y$ takes a Bernoulli distribution with probability $\Phi(f(\x))$, and $\Phi$ is the cumulative distribution function of the normal distribution. For further details on GPC see \citep{Rasmussen2006}.

Posterior inference in the GPC model is intractable; given some observations $\data$, the posterior over $f$ becomes non-Gaussian and complicated. This is addressed by using approximate inference methods. The most commonly used approximate inference methods for Gaussian process classification are expectation propagation \citep[EP,][]{Minka2002}, Laplace's approximation \citep{williams1998}, assumed density filtering \citep[ADF,][]{csato2000} and sparse methods \citep{candela05sparseGP}. These all approximate the non-Gaussian posterior by a Gaussian \citep{Nickisch2008}, but differ in the optimisation criterion and other restrictions. Throughout this chapter I will assume that we are provided with some Gaussian approximation to the GPC posterior resulting from one of these methods, though the active learning method is agnostic as to which method produced this estimate. Given the sequential nature of active learning, fast on-line methods \citep{Csato2002} are particularly well suited for the task. In our derivation we will use {\scriptsize$\stackrel{1}{\approx}$} to indicate where approximate inference is exploited.

\subsection{Computing the value of information}

Now, we will compute the informativeness of a query $\x$ using Eqn.\  \eqref{eqn:rearrangement}. Recall that now the parameter $\param$ is the latent function $f$:

\begin{align}
	&\argmax_{\x} H[\y \vert \x, \data] - \expect{f\sim p(\param|\data)} \left[ H[\y \vert \x,f] \right]
\end{align}

To evaluate the objective one has to compute expectations over the posterior $p_\data$. As discussed earlier, we use a Gaussian approximation to the posterior, so that for each $\x$, $f_{\x} = f(\x)$ follows a Gaussian distribution with mean $\mu_{\x,\data}$ and variance $\sigma_{\x,\data}^2$. The exact value of $\mu_{\x,\data}$ and $\sigma_{\x,\data}^2$ depend on the approximation scheme used as well as the covariance kernel.

\begin{align}
	p(f_{\x}\vert\data) \stackrel{1}{\approx} \mathcal{N}(f_{\x}\vert \mu_{\x,\data},\sigma_{\x,\data}^2) 
\end{align}

To compute the two terms in Eqn.\ \eqref{eqn:rearrangement} we have to compute two entropy quantities. $H[y\vert\x,f]$, the entropy of the binary output variable $y$ given a fixed $f$ can be expressed in terms of the binary entropy function $h$: 
\begin{align}
	H[y\vert\x,f] &= h\left(\Phi(f(\x)\right)\\
	h(p)	&=- p\log p - (1-p)\log(1-p)
\end{align}

Similarly, the first term in Eqn.\ \eqref{eqn:rearrangement}, $H[y\vert\x,\data]$ can be computed analytically:

\begin{align}
	H[y\vert\x,\data] &= h\left( \int \Phi( f_{\x} ) p(f_{\x}\vert\data) df_{\x} \right)\\
	&\stackrel{1}{\approx} h\left( \int \Phi( f_{\x} )  \mathcal{N}(f_{\x}\vert \mu_{\x,\data},\sigma_{\x,\data}^2) df_{\x} \right) \\
	&= h \left( \Phi\left( \frac{\mu_{\x,\data}}{\sqrt{\sigma^2_{\x,\data} + 1}} \right)\right)\label{ent_mean},
\end{align}
where we used the fact that the sum of Gaussian variables is Gaussian distributed. This trick is only possible because in probit classification the link function $\Phi(\cdot)$ can be interpreted as the cumulative distribution function of a Normal distribution. In logistic regression, instead of the Gaussian CDF, one would use a logistic sigmoid where the same trick cannot be applied and further approximations are required.

The last quantity needed for evaluating the BALD objective function is the expectation $\expect{f\sim p(\param|\data)} \left[ H[\y \vert \x,f] \right]$. Unfortunately, for GPC this quantity cannot be computed in closed form, even assuming a Gaussian approximation to the posterior. However, with a further approximation (denoted by $\stackrel{2}{\approx}$), the expectation can be accurately approximated as follows.

\begin{align}
	\expect{f \sim p(f\vert\data)} \left[ H[\y\vert f] \right] &\stackrel{1}{\approx}\int h(\Phi(f_{\x})) \mathcal{N}(f_{\x}\vert \mu_{\x,\data},\sigma_{\x,\data}^2)df_{\x}\label{eqn:mean_entropy}\\
	&\stackrel{2}{\approx} \int \exp\left(-\frac{f_{\x}^2}{\pi\ln2}\right) \mathcal{N}(f_{\x}\vert \mu_{\x,\data},\sigma_{\x,\data}^2)df_{\x}\\	
	&= \frac{C}{\sqrt{\sigma_{\x,\data}^2 + C^2}}\exp\left(-\frac{\mu_{\x,\data}^2}{2\left(\sigma_{\x,\data}^2 + C^2\right)}\right),
\end{align}
where $C=\sqrt{\frac{\pi\ln2}{2}}$. The first approximation, {\scriptsize $\stackrel{1}{\approx}$}, reflects the Gaussian approximation to the posterior, as before.

The integral in the left hand side of Eqn.\ \eqref{eqn:mean_entropy} is hard to compute; the non-linear function $h(\Phi(\cdot))$ must be integrated against a Gaussian distribution. However, $h(\Phi(t))$ can be approximated accurately by an unnormalised Gaussian curve, $\exp(-t^2/\pi\ln2)$, making the integral trivial to compute via convolution formul\ae for Gaussian distributions.

Consider the Taylor expansion of $g \defeq \log(h(\Phi(\cdot)))$.

\begin{align}
	g(t) &= g(0) + \frac{g'(0)t}{1!} + \frac{g''(0)t^2}{2!} + \dots
\end{align}

The derivatives in the formula can be computed in closed form using the chain rule

\begin{align}
	g(t) &= \log(h(\Phi(t)))\\
	g'(t) &= -\frac{1}{\log 2}\frac{\Phi'(t)}{h(\Phi(t))}\left[\log\Phi(t) - \log(1-\Phi(t))  \right) \nonumber \\ 
	f''(t) &= \frac{1}{\log 2}\frac{\Phi'(t)^2}{h(\Phi(t))^2}\left(\log\Phi(t) - \log(1-\Phi(t))  \right)\nonumber\\
	& \qquad - \frac{1}{\log 2}\frac{\Phi''(t)}{h(\Phi(t))}\left(\log\Phi(t) - \log(1-\Phi(t))  \right) \nonumber\\
	& \qquad - \frac{1}{\log 2}\frac{\Phi'(t)^2}{h(\Phi(t))}\left(\frac{1}{\Phi(t)} + \frac{1}{(1-\Phi(t)})  \right) \nonumber\\
\end{align}

Therefore the following Taylor series approximation holds:

\begin{align}
	\log h(\Phi(t)) &\stackrel{2}{\approx} - \frac{1}{\pi\log 2}t^2
\end{align}

Consequently, exponentiating both sides we can make the following Gaussian approximation to $h(\Phi(\cdot))$:

\begin{equation}
	h(\Phi(t))\stackrel{2}{\approx}\exp\left({-\frac{t^2}{\pi\log 2}}\right)
\end{equation}

\begin{figure}
	\centering
	\begin{tikzpicture}
	\node at (0,0) {
	\resizebox{.55\columnwidth}{!}{\input{figs/BALD/GPC/gaussian_approx.tikz}}};
	\node at (.47\columnwidth,0){
	\resizebox{.45\columnwidth}{!}{
	\begin{tabular}{|c|c|c|c|}
	\hline
	&MCMC&EP ($\stackrel{1}{\approx}$)&Laplace ($\stackrel{1}{\approx}$)\\ \hline
	\hline
	MC & 0 & $7.51\pm2.51$ & $41.57\pm4.02$ \\
	$\stackrel{2}{\approx}$ & $0.16\pm0.05$ & $7.43\pm2.40$ & $40.45\pm3.67$ \\ \hline
	\end{tabular}
	}};
	\end{tikzpicture}

	\caption[Taylor series approximation to the value of information in GP classification]{\emph{Left:} Analytic approximation ({\scriptsize $\stackrel{1}{\approx}$}) to the binary entropy of the error function (\ref{plots:approx_true}) by a squared exponential (\ref{plots:approx_approx}). The absolute error (\ref{plots:approx_error}) remains under $3\cdot 10^{-3}$. \emph{Right:} Percentage approximation error ($\pm$1 s.d.) for different methods of approximate inference (\emph{columns}) and approximation methods for evaluating Eqn.\eqref{eqn:mean_entropy} (\emph{rows}). The results indicate that {\scriptsize $\stackrel{2}{\approx}$} is a very accurate approximation; EP causes some loss and Laplace significantly more, which is in line with the comparison presented in \citep{Kuss2005}. }\label{fig:trick}
\end{figure}

Fig.\ \ref{fig:trick} depicts the striking accuracy of this approximation. The maximum possible error that will be incurred when using this approximation in the BALD formula is if the approximate posterior $\mathcal{N}(f_{\x}\vert \mu_{\x,\data},\sigma_{\x,\data}^2)$ is centred at $\mu_{\x,\data}=\pm 2.05$  with $\sigma_{\x,\data}^2$ tending to zero (see Fig.\ \ref{fig:trick}, absolute error \ref{plots:approx_error}); even this yields only a 0.27\% error in the integral in Eqn.\eqref{eqn:mean_entropy}.

In subsequent sections we investigate experimentally the information lost from approximations {\scriptsize $\stackrel{1}{\approx}$} and {\scriptsize $\stackrel{2}{\approx}$} as compared to the gold standard of extensive Monte Carlo simulation.

To summarise, the BALD algorithm for Gaussian process classification consists of two steps. First it applies an approximate inference algorithm to obtain the posterior predictive mean $\mu_{\x,\data}$ and $\sigma_{\x,\data}$ for each point of interest $\x$. Then, it selects a query $\x$ that maximises the following objective function:

\begin{equation}
	\mathrm{h} \left( \Phi\left( \frac{\mu_{\x,\data}}{\sqrt{\sigma^2_{\x,\data} + 1}} \right)\right) - \frac{C \exp\left(-\frac{\mu_{\x,\data}^2}{2\left(\sigma_{\x,\data}^2 + C^2\right)}\right)}{\sqrt{\sigma_{\x,\data}^2 + C^2}} \label{eqn:BALD_GPC}
\end{equation}

For most practically relevant kernels the objective \eqref{eqn:BALD_GPC} is smooth and differentiable function of $\x$, so gradient-based optimisation procedures can be used to find the maximally informative query.
	
% ########  ########  ######  ##     ## ##       ########  ######      ######   ########   ######  
% ##     ## ##       ##    ## ##     ## ##          ##    ##    ##    ##    ##  ##     ## ##    ## 
% ##     ## ##       ##       ##     ## ##          ##    ##          ##        ##     ## ##       
% ########  ######    ######  ##     ## ##          ##     ######     ##   #### ########  ##       
% ##   ##   ##             ## ##     ## ##          ##          ##    ##    ##  ##        ##       
% ##    ##  ##       ##    ## ##     ## ##          ##    ##    ##    ##    ##  ##        ##    ## 
% ##     ## ########  ######   #######  ########    ##     ######      ######   ##         ######  

\section{Experiments and results}

\subsection{Quantifying approximation losses}

Recall that to obtain Eqn.\ \eqref{eqn:BALD_GPC} we made two approximations: we perform approximate inference ({\scriptsize $\stackrel{1}{\approx}$}), and we approximated the binary entropy of the Gaussian CDF by a squared exponential ({\scriptsize $\stackrel{2}{\approx}$}). Both of these can be substituted with extensive Monte Carlo approximation, enabling us to compute a near-exact, unbiased estimate of the expected information gain. Using extensive Monte Carlo as the `gold standard', we can evaluate how much we loose by applying these approximations. We quantify approximation error as: 

\begin{align}
	\frac{ \max_{\x\in\X} I(\x) - I(\argmax_{\x\in\X}\hat{I}(\x)) }{{\max_{\x\in\X}I(\x) }}\cdot 100\%,
\end{align}
where $I$ is the objective computed using Monte Carlo, $\hat{I}$ is the approximate objective. We have run experiments on the Lung Cancer (\emph{cancer}) classification dataset \citep{Hong1991} downloaded from the UCI Machine Learning Repository \citep{UCIRepository}. Results are shown and discussed in Figure \ref{fig:trick}. In general we see that the approximation error from approximate inference ({\scriptsize $\stackrel{1}{\approx}$}) typically outweighs the negligible error introduced by the Taylor-series approximation ({\scriptsize $\stackrel{2}{\approx}$}).

\subsection{Pool based active learning}

We test BALD for GPC and preference learning in the pool-based setting \ie selecting $x$ values from a fixed set of potential query locations. We compare to eight other algorithms discussed in this paper: random sampling, maximum entropy sampling (MES), query by committee (QBC), support vector machine (SVM) with version space approximation \cite{Tong2002}, decision theoretic approaches from \citep{Kapoor2007, Zhu2003} and direct minimisation of expected empirical error. The latter method is not widely used, but is included for analysis of \cite{Kapoor2007}.

First we consider three artificial, but challenging, datasets in two dimensional input space $\Xe = \mathbb{R}^2$. These datasets are designed to exaggarate problematic edge cases that often cause active learning methods to fail. The first, \emph{block in the middle}, has a block of noisy, randomly labeled points on the decision boundary between two otherwise clearly separable classes. The second, \emph{block in the corner}, has a block of uninformative points far from the decision boundary. A capable active learning algorithm should avoid these uninformative regions. The third data set, similar to the \emph{checkerboard} dataset used in \cite{Zhu2003}, is designed to test the algorithm's capabilities to find multiple disjoint islands of points from one class. 

The three datasets and results using each algorithm are depicted in Fig.\ \ref{fig:artificial}. We can see that BALD (\ref{plots:BALD}) handles all three artificial datasets well. Transductive criteria, \citet{Kapoor2007} (\ref{plots:dec}) and \citet{Zhu2003} (\ref{plots:semi}), struggle on the \emph{block in the middle} dataset, because the random noise added to the central block of points dominates the risk of classification. In the third toy example, \emph{checkerboard}, they are very effective in exploring the centre of each island of data points early on.

\begin{figure}
	\begin{center}
	\begin{tabular}{ccc}
	\input{figs/BALD/GPC/blockinthemiddle_dataset.tikz}&
	\input{figs/BALD/GPC/corner_dataset.tikz}&
	\input{figs/BALD/GPC/checkerboard_dataset.tikz}\\
	\input{figs/BALD/GPC/blockinmiddle2.tikz}&
	\input{figs/BALD/GPC/blockincorner2.tikz}&
	\input{figs/BALD/GPC/checkerboard2.tikz} \\
	\end{tabular}
	\end{center}
	\caption[Evaluation of Bayesian active learning on artificial data sets]{\emph{Top:} Artificial data sets used in our evaluation of active learning methods. Exemplars of the two classes are shown with black squares (\ref{plots:positives}) and red circles (\ref{plots:negatives}). \emph{Bottom:} Results of active learning with nine methods: random query (\ref{plots:rand}), BALD (\ref{plots:BALD}),  MES (\ref{plots:maxent}), QBC with the vote criterion with 2 ($\mbox{QBC}_2$, \ref{plots:QBC2}) and 100 ($\mbox{QBC}_{100}$, \ref{plots:QBC100}) committee members, active SVM (\ref{plots:SVM}), IVM (\ref{plots:IVM}), \citet{Kapoor2007} (\ref{plots:dec}), \citet{Zhu2003} (\ref{plots:semi}) and empirical error (\ref{plots:emp}).}
	\label{fig:artificial}
\end{figure}

In addition to this, we present results on 8 real-world classification datasets from the UCI Machine Learning Repository \citep{UCIRepository}: \emph{australia, crabs, wine, vehicle, isolet, cancer, letter} and \emph{wdbc}. \emph{Letter} is a multiclass dataset from which we select hard-to-distinguish letters E vs.\ F and D vs.\ P as binary sub-problems. Results on these data sets are plotted in Fig.\ \ref{fig:BALD_GPC_results}.

\begin{figure}
	\begin{center}
	\begin{tabular}{ccc}
	\input{figs/BALD/GPC/crabs2.tikz}&
	\input{figs/BALD/GPC/vehicle2.tikz}&
	\input{figs/BALD/GPC/wine2.tikz}\\
	\input{figs/BALD/GPC/wdbc2.tikz}&
	\input{figs/BALD/GPC/isolet2.tikz}&
	\input{figs/BALD/GPC/austra2.tikz}\\
	\input{figs/BALD/GPC/letterDP2.tikz}&
	\input{figs/BALD/GPC/letterEF2.tikz}&
	\input{figs/BALD/GPC/cancerB2.tikz}
	\end{tabular}
	\end{center}
	\caption[Evaluation of Bayesian active learning on real-world data sets]{Evaluation of the accuracy of active learning algorithms on various real-world classification datasets. Methods used are random query (\ref{plots:rand}), BALD (\ref{plots:BALD}),  MES (\ref{plots:maxent}), QBC with 2 ($\mbox{QBC}_2$, \ref{plots:QBC2}) and 100 ($\mbox{QBC}_{100}$, \ref{plots:QBC100}) committee members, active SVM (\ref{plots:SVM}), IVM (\ref{plots:IVM}), decision theoretic \citep{Kapoor2007} (\ref{plots:dec}), semi-supervised \citep{Zhu2003} (\ref{plots:semi}) and empicial error (\ref{plots:emp}). The decision theoretic methods took a long time to run, so were not completed for all data sets. Plots (a-i) correspond to different classification datasets from the UCI Machine Learning Repository. Plot (i) includes BALD with hyper-parameter learning (\ref{plots:opthyper}). See text for analysis. \label{fig:BALD_GPC_results}}
\end{figure}

We can see from Figs \ref{fig:artificial} and \ref{fig:BALD_GPC_results} that by using BALD we make significant gains over na\"{i}ve random sampling in both the classification and preference learning domains. Relative to other active learning algorithms BALD performs consistently well across all datasets, particularly when avoiding the block of points in Fig.\ \ref{fig:artificial} (a). Occasionally \eg as Fig.\ \ref{fig:BALD_GPC_results} (i), it performs poorly on the first couple of queries.

In most of the reported experiments I have fixed the kernel $k$ of the Gaussian process prior to the maximum likelihood estimate on the whole pool. This is of course cheating, as it uses information from the whole dataset before starting to select queries, but it provides us with a fair way of comparing various methods, including those that cannot handle hyperparameter learning. As described in \citep{Houlsby2011,Houlsby2012preference}, BALD can accommodate active learning of hyperparameters. In Fig.\ \ref{fig:BALD_GPC_results} (i) we also show the performance of this method, and on the \emph{cancer} dataset it helps to overcome the initial poor performance of BALD.

MES often performs as well as BALD \eg on Fig.\ \ref{fig:artificial}(c), where there is no label noise. It never outperforms BALD though and on noisy datasets (\eg Fig.\ \ref{fig:artificial}(a)) performs particularly poorly as expected. QBC provides a close approximation to BALD and usually provides a small decrement in performance. However, there is a large decrease in performance on the noisy artificial dataset caused by the vote criterion not maintaining a notion of inherent uncertainty, like MES. The IVM occasionally performs well, but often exhibits highly pathological behaviour; by observing $\y$ values in advance it actively chooses noisy or mislabelled points, thinking them informative. The SVM-based approach exhibits variable performance (it does extremely well on Fig.\ \ref{fig:BALD_GPC_results} (f), but very poorly on \ref{fig:artificial} (c)).

On the real datasets though BALD usually performs as well, if not better, than transductive methods of \citet{Kapoor2007} and \citet{Zhu2003}, despite not having access to the locations of the test points and having a significantly lower computational cost. The \citep{Kapoor2007} objective sometimes fails badly, this is likely to be because one term in their objective function is the empirical error. The weighting of this term is determined by the relative sizes of the training and test set. Directly minimizing empirical error usually performs very pathologically, picking only `'safe' points; when the \citep{Kapoor2007} objective assigns too much weight to this term it also fails.

% ########  ########  ######## ######## ######## ########  ######## ##    ##  ######  ######## 
% ##     ## ##     ## ##       ##       ##       ##     ## ##       ###   ## ##    ## ##       
% ##     ## ##     ## ##       ##       ##       ##     ## ##       ####  ## ##       ##       
% ########  ########  ######   ######   ######   ########  ######   ## ## ## ##       ######   
% ##        ##   ##   ##       ##       ##       ##   ##   ##       ##  #### ##       ##       
% ##        ##    ##  ##       ##       ##       ##    ##  ##       ##   ### ##    ## ##       
% ##        ##     ## ######## ##       ######## ##     ## ######## ##    ##  ######  ######## 

\subsection{Summary}

In this chapter I introduced BALD for Gaussian process classification as a practical algorithm for perfoming Bayesian active learning in binary classification tasks. The algorithm was based on two approximations: approximate posterior inference and Taylor-series approximation to the BALD information criterion. I showed that these approximations do not result in substantial loss of precision and that BALD performs well in a variety of practical datasets. In the following section I will extend the algorithm to handle problems that cannot be modelled as binary classification and show that the performance of BALD is fvourable in those situations as well.

\section{Extension to preference elicitation}

It is possible to extend the above framework to handle a practically highly relevant problem of learning peoples' preferences. People have rich knowledge and information about which products, services, people, items they prefer, find attractive or like. Methods that uncover this knowledge are invaluable in a number of commercial and science applications. Examples include:
\begin{description}
	\item [market research and e-commerce:] learning about users' preferences of products, prices, or brands. Preferences can be exploited to maximise user satisfaction and to drive profit
	\item [social media:] identifying people whom their peers find influential, reliable, trustworthy or knowledgeable in certain topics. This information can be used to find domain experts, or to drive influence marketing
	\item [recommendation:] on review websites collecting and quantifying user feedback on restaurants, activities, movies, music albums, etc. to power recommendations
	\item [research:] learning about difficult, subjective concepts such as attractiveness, for example investigating which features determine perceived attractiveness
	\item [equipment calibration:] calibration of parameters to improve perceived subjective quality. Examples include calibrating sound quality of hearing aids or stereo equipment, high-dimensional parameter optimisation in digital image rendering
\end{description}

Many existing approaches -- such as traditional market research surveys, restaurant review websites, DVD rental websites, etc -- require human respondents\footnote{Throughout this chapter I will use the words person, respondent and user interchangeably to mean the person whose preferences we are interested in predicting.} to give ratings of items on an absolute scale. Market research surveys often use a scale of 1 to 7, while review websites use star ratings, typically on a scale between 1 to 5 stars. There are multiple problems with this approach.
\begin{enumerate}
	\item People's baseline level on the absolute scale may differ. One person's 4 star rating may describe the same level of satisfaction as someone else's 5 stars. This makes aggregating opinions from many different people a non-trivial task
	\item The variance of responses may also differ across people: some more conservative reviewers would never use the extreme 1 star or 5 star ratings, whilst other respondents' opinions may be more polarised
	\item To give informed ratings, the user has to know the distribution of the quality of items ahead of time. They may prefer not to give a maximal 5-star rating to an item, because they don't know if better items exist. Others may give 5-star to a mediocre item, because they have never seen a better alternative.
\end{enumerate} 

To overcome the limitations of an absolute scale, an increasing number of applications are performing preference elicitation via pairwise item comparisons. In this case, the respondent is presented a pair of items, and they have to judge which of the two alternatives is more preferable. In cognitive science, this type of preference elicitation is known as two-alternative forced choice, or 2AFC for short \citep{Fechner1860,Platt1999,Huszar2010}. The machine learning community often refers to this kind problem as \emph{binary preference elicitation}, preference learning or learning to rank \citep{Chu2005,furnkranz2010}.

Crucially, binary preference elicitation sidesteps most of the problems that eliciting preference on an absolute scale exhibits. Because no absolute scale is used, it does not matter if the scale of ratings used by different respondents are not aligned, as long as there is a mostly monotonic relationship between them. Also, the respondent only needs to be knowledgeable about the two items being compared in order to give an informed response. This way respondents with much more limited scope of knowledge can provide highly informative data.

Despite these convenient properties, pairwise preference learning has a drawback. When learning preferences over $n$ items, there are $\mathcal{O}(n^2)$ potential pairs of items that we can ask the respondents to compare. Not only would querying all item-pairs take prohibitively long time, it is also unnecessary. Most binary choices would be predictable from previous choices the respondent or other respondents have already made.

Therefore, in binary preference learning, active learning and optimal experiment design have increased importance, and increased potential to improve over passive learning.

In this section I will extend the BALD framework developed for Gaussian process classification to work on preference learning. I will do this by showing how a popular non-parametric model for preference learning can be interpreted as binary Gaussian process classification with an special positive definite kernel between item-pairs, that I call \emph{the preference kernel}. This idea can be used in other kernel-based classifiers such as SVMs. I present experimental results where I compare BALD to other active learning approaches to this problem.

\subsection{Reduction to classification\label{sec:prefKernel}}

In preference learning each data point describes two items, $i$ and $j$, which have been presented to a human judge. It is assumed that the items are described by their numeric feature vectors $\x_i\in\mathcal{X}$ and $\x_j\in\mathcal{X}$ respectively. Each item is assumed to have a fixed number, $\dim(\mathcal{X})=d$, of features associated with them. Each training data point also has a binary label $y\in\{-1,1\}$ such that $y=1$ if the user prefers item $i$ to item $j$, and $y=-1$ otherwise. The primary goal of preference learning is to accurately predict the direction of human preference for a new pair of feature vectors not seen before.

Pairwise preference learning is a special case of binary classification, inasmuch as the main goal is to predict a class label $y\in\{-1,1\}$ given an input feature vector $(\x_i,\x_j)\in\mathcal{X}^2$, composed by concatenating features of $i$ and $j$. However, using a generic classifier, such as an SVM or Gaussian process classifier would be highly inefficient, as these classifiers do not know about the symmetry inherent in the ranking problem. Firstly, if one observes $(\x_i,\x_j)$ pair with a positive label, that implies the pair $(\x_j,\x_i)$ would have a negative label. Furthermore, if one observes $\x_i$ is preferred to $\x_j$ and $\x_j$ is preferred to $\x_k$, one would predict $\x_i$ is preferred to $\x_k$. A generic classifier trained on pairs cannot make such deductions.

This problem is often addressed by introducing a latent preference function $f:\mathcal{X}\mapsto \mathbb{R}$ such that
$f(\x_i) > f(\x_j)$ whenever the user prefers item $i$ to item $j$ and $f(\x_i) < f(\x_j)$ otherwise \citep{Chu2005}. This latent representation implies a pre-defined ordering of items. However, the observed data are not always consistent with a single fixed ordering, and sometimes are contradictory. Furthermore people's choices may be contaminated by noise, or be inaccurate because of lack of attention. To account for this randomness, the model presented by \citet{Chu2005} assumes that when respondents decide between options, their preference function is contaminated by evaluation noise.

When the evaluations of $f$ are contaminated with Gaussian noise with zero mean and (without loss of generality) variance $1/2$, we obtain the following likelihood function for the underlying preference function $f$ given the data point $\x_i$, $\x_j$ and corresponding label $y$:

\begin{align}
\mathbb{P}(y|\x_i,\x_j,f) &= \Phi[(f[\x_i] - f[\x_j])y]\,,\label{eqn:preference_likelihood}
\end{align}
where $\Phi$ is the standard Normal cumulative distribution function. The preference learning problem can be solved via Bayesian inference, combining a GP prior on $f$ with the likelihood function in (\ref{eqn:preference_likelihood}) \citep{Chu2005}. The posterior for $f$ can then be used to make predictions on the user preferences for new pairs of items.

Note that the likelihood (\ref{eqn:preference_likelihood}) depends only on the difference between $f(\x_i)$ and $f(\x_j)$.
Let $g:\mathcal{X}^2\mapsto\mathbb{R}$ be the latent function $g(\x_i,\x_j) = f(\x_i) - f(\x_j)$.
We can recast the inference problem in terms of $g$ and ignore $f$. When the evaluation of $f$ is contaminated with standard Gaussian noise as before, the likelihood for $g$ given $\x_i$, $\x_j$ and $y$ is

\begin{align}
\mathbb{P}(y|\x_i,\x_j,g) &= \Phi[g(\x_i, \x_j)y]\,.\label{eqn:preference_likelihood2}
\end{align}

Note this likelihood functon for $g$ is the same as the probit classification likelihood defined in Eqn.\ \eqref{eqn:GPC_model}. Since $g$ is obtained from $f$ through a linear operation, the GP prior on $f$ induces a GP prior on $g$. The prior covariance function $k_\text{pref}$ of the GP prior on $g$ can be computed from the covariance function $k$ of the GP on $f$ as follows (assuming zero mean prior for $f$).

\begin{align}
	k_\text{pref}&((\x_i,\x_j),(\x_k,\x_l)) = \cov{f\sim GP_k}{g(\x_i,\x_j)}{g(\x_k,\x_l)}\\
	&= \cov{f\sim GP_k}{f(\x_i)-f(\x_j)}{f(\x_k) - f(\x_l)}\\
	&= \expect{f\sim GP_k}\left[\left(f(\x_i)-f(\x_j)\right)\left(f(\x_k)-f(\x_l)\right)\right]\\
	&= \expect{f\sim GP_k}f_{\x_i}f_{\x_k} + \expect{f\sim GP_k}f_{\x_j}f_{\x_l} - \expect{f\sim GP_k}f_{\x_i}f_{\x_l} - \expect{f\sim GP_k}f_{\x_j}f_{\x_k}\\
	&= k(\x_i,\x_k) + k(\x_j,\x_l) - k(\x_i,\x_l) - k(\x_j,\x_k) \label{eqn:preference_kernel}
\end{align}

We call $k_\text{pref}$ the \emph{preference kernel}. This kernel function for preference learning is not new: the same kernel has been derived from a large margin classification viewpoint by \citet{furnkranz2010}. However, to our knowledge, the preference kernel has not been used previously in Bayesian, Gaussian process-based models, only in our previous work \citep{Houlsby2011,Houlsby2012preference}

The combination of (\ref{eqn:preference_likelihood2}) with a GP prior based on the preference kernel allows us to transform the pairwise preference learning problem into  binary classification with GPs. This means that state-of-the-art methods for GP binary classification, such as expectation propagation \citep{Minka2001}, can be applied readily to preference learning. Furthermore, the simplified likelihood (\ref{eqn:preference_likelihood2}) allows us to implement complex inference problems such as the multi-user hierarchical model described in \citep{Houlsby2012preference}.

\subsection{Experiments and results}

To test the performance of BALD on preference learning we use the \emph{cpu, cart} and \emph{kinematics} regression datasets from the LIACC Machine Learning Data Set Repository \citep{LIACCRepository}. We processed each of these data sets to yield a binary preference task following the procedure described in in \cite{Chu2005}: Pairs of items were randomly selected and regression target values were used to decide the direction of preference to form a pool of training points for pool-based active learning. The performance was tested on a held-out test data set generated in a similar fashion.

Results on the three datasets are shown in Fig.\ \ref{fig:BALD_pref_results}.  Surprisingly, despite our expectations, we found that random sampling from the pool provides reasonable performance, and active selection of measurements does not radically improve the speed of learning. Across the three data sets all studied methods perform well. BALD seems to struggle in the initial phase of learning on the \emph{cpu} dataset, for which I did not find a convincing explanation. On the \emph{kinematics} dataset the difference between methods is more apparent, and here BALD provides the best performance among all methods tested.

In follow-up work we extended BALD to collaborative preference learning, where preference judgements are elicited from multiple experts \citep{Houlsby2012preference}. The interested reader is referred to this paper for further experimental validation involving real-world preference datasets.
% 
\begin{figure}
	\begin{center}
	\begin{tabular}{ccc}
	\input{figs/BALD/GPC/prefcpu2.tikz}&
	\input{figs/BALD/GPC/prefcart2.tikz}&
	\input{figs/BALD/GPC/prefkinem2.tikz}
	\end{tabular}
	\end{center}
	\caption[Evaluation of Bayesian active learning of binary preference relations]{Evaluation of the accuracy of active learning algorithms on various binary preference learning datasets. Methods used are random query (\ref{plots:rand}), BALD (\ref{plots:BALD}),  MES (\ref{plots:maxent}), QBC with 2 ($\mbox{QBC}_2$, \ref{plots:QBC2}) and 100 ($\mbox{QBC}_{100}$, \ref{plots:QBC100}) committee members, active SVM (\ref{plots:SVM}), IVM (\ref{plots:IVM}), decision theoretic \citep{Kapoor2007} (\ref{plots:dec}). For prediction, each method uses Gaussian process classification or SVM with the preference kernel from Eqn.\ \eqref{eqn:preference_kernel}.  See text for analysis. \label{fig:BALD_pref_results}}
\end{figure}

\section{Summary and conclusions}

In this chapter I presented BALD, or Bayesian active learning by Disagreement, a practical algorithm for Bayesian active learning based on Shannon's mutual information. BALD exploits the symmetry of Shannon's mutual information and expresses the well known criterion in terms of the Shannon entropy of predictive distributions in the observation space. We have shown how BALD can be implemented to perform Bayesian active classification and preference learning in state-of-the art Gaussian process-based models in a computationally efficient way. Our experiments show that BALD compares favourably to other active learning methods, including the popular active SVMs \citep{Tong2002}.

Unfortunately, as BALD is built on the unique symmetry property of Shannon's mutual information, it does not generally apply to other instances of the scoring rule-based active learning framework described in Chapter \ref{sec:active_learning_framework}. Indeed, among the examples of scoring rules given in Chapter \ref{sec:scoring_rules}, no other value of information functional is symmetric.