%!TEX root = ../main.tex



\section{Gaussian process classification}

\paragraph{Summary of contributions and published work} The work presented in this chapter has been carried out in collaboration with Neil M.\ T.\ Houlsby(NMTH), Jose Miguel Hernandez-Lobato (JMHL), Zoubin Ghahramani(ZG) and Máté Lengyel(ML). This work forms the basis of the technical report \citep{arxivBALD} and the peer-reviewed conference paper \citep{NIPS2012}. In addition, elements of this work have also been presented by Ferenc Huszár and NMTH at the NIPS 2011 workshops ``Preferenc Learning'' and ``Bayesian Optimization and Active Learning''. All authors contributed equally to the design of the research and to the development of statistical models. The derivation of the preference kernel eqn.\ \eqref{} and the approximation to the BALD formula in eqn.\ \eqref{} are original contributions by Ferenc Huszár. Computational experiments were run and the results were interpreted using MATLAB and R by Ferenc Huszár, NMTH and JMHL.

\subsection{Approximate BALD for GPC}
\subsection{Results}
\subsection{Conclusions}

\section{Preference elicitation}

In this section I address the practical problem of learing peoples' preferences. People have rich knowledge knowledge and information about which products, services, people, items they prefer, find attractive or like. Methods that uncover this private knowledge is invaluable in a number of commercial and science applications. Examples include
\begin{description}
	\item [market research and e-commerce:] learning about users' preferences of products, prices, or brands. Preferences can be exploited to maximise user satisfaction and to drive profit
	\item [social media:] identifying people that their peers find influential, reliable, trustworthy or knowledgable on certain topics
	\item [recommendation:] on review websites collecting and quantifying user feedback on restaurants, activities, movies, music albums, etc. to power recommendations
	\item [research:] learning about difficult, subjective concepts such as attractiveness, for example investigating which features determine perceived attractiveness
	\item [equipment calibration:] calibration of parameters to improve perceived subjective quality. Examples include calibrating sound quality of hearing aid or stereo equipment, high-dimensional parameter optimisation in digital image rendering
\end{description}

Many extisting approaches -- such as traditional market research surveys, restaurant review websites, DVD rental websites, etc -- require human respondents to give ratings of items on an absolute scale. Market research surveys often use a scale of 1 to 7, while review websites use star ratings, typically on a scale between 1 to 5 stars. There are multiple problems with this approach.
\begin{enumerate}
	\item People's baseline level on the absolute scale may differ. One person's 4 star rating may describe the same level of satisfaction as someone else's 5 star rating. This makes aggregating opinions from many different people a non-trivial task
	\item The variance of responses may also differ across people: some more conservative reviewers would never use the extreme 1 star or 5 star ratings, whilst other respondents' opinions may be more polarised
	\item To give informed ratings, the user has to know the distribution of the quality of items ahead of time. They may prefer not to give a maximal 5-star rating to an item, because they don't know if better items exist. Others may give 5-star to a mediocre item, because they have never seen a better alternative.
\end{enumerate} 

To overcome the limitations of an absolute scale, in an increasing number of applications preference elicitation is done via pairwise item comparisons. In this case, the respondent is presented a pair of items, and they have to judge which of the two alternatives is more preferable. In cognitive science, this type of preference elicitation is known as two-alternative forced choice, or 2AFC for short \citep{2AFC}. The machine learning community often refers to this kind problem as \emph{binary preference elicitation}, preference learning or learning to rank.

Crucially, binary preference elicitation sidesteps most of the problems that eliciting preference on an absolute scale exhibits. Because no absolute scale is used, it does not matter if the scale of ratings used by different respondents are not aligned, as long as there is a mostly monotonic relationship between them. Also, the respondent only needs to be knowledgeable about the two items being compared in order to give an informed responce. This way respondents with much more limited scope of knowledge can provide highly informative data.

Despite these convenient properties, pairwise preference learning has a drawback. When learning preferences over $n$ items, there are $\mathcal{O}(n)$ potential pairs of items that we can ask the respondents to compare. Not only would querying all item-pairs take prohibitively long time, it is also unneccessary. Most binary choices would be predictable from previous choices the respondent or other respondents have already made.

Therefore, in binary preference learning, active learning and optimal experiment design has increased importance, and increased potential to improve over passive learning.

In this section I will extend the BALD framework developed for Gaussian process classification to work on preference learning. I will do this by showing how a popular nonparametric model for preference learning can be interpreted as binary Gaussian process classification with an special positive definite kernel between item-pairs, that I call \emph{the preference kernel}. I also present an extension of the model which can be applied to learn from preference choices expressed by multiple users, even if different users disagree in their preferences. The experimental results presented in this chapter show that the Gaussian-process-based models combined with the BALD framework are very competitive and on many datasets surpass state-of-the art levels of performance.

\subsection{Formal framework\label{sec:prefKernel}}

In preference learning each datapoint describes two items, $i$ and $j$, which have been presented to a human judge. It is assumed throughout this thesis that the items are described by their numeric feature vectors $\mathbf{x}_i\in\mathcal{X}$ and $\mathbf{x}_j\in\mathcal{X}$ respectively. Each item is assumed to have a fixed number, $\dim(\mathcal{X})=d$, of features associated with them. Each training datapoint also has a binary label $y\in\{-1,1\}$ such that $y=1$ if the user prefers item $i$ to item $j$, and $y=-1$ otherwise. The primary goal of preference learning is to accurately predict the direction of human preference for a new pair of feature vectors not seen before.

The problem of pairwise preference learning is an instance of binary classification, inasmuch as the main goal is to predict a class label $y\in\{-1,1\}$ given an input feature vector $(\mathbf{x}_i,\mathbf{x}_j)\in\mathcal{X}^2$. However, using a generic classifier, such as an SVM or Gaussian process classifier would be highly inefficient, as these classifiers do not know about the symmetries inherent in the ranking problem. Firslty, if one observes $(\mathbf{x}_i,\mathbf{x}_j)$ pair with a positive label, that implies the pair $(\mathbf{x}_j,\mathbf{x}_i)$ would have a negative label. Furthermore, if one observes $\mathbf{x}_i$ is preferred to $\mathbf{x}_j$ and $\mathbf{x}_j$ is preferred to $\mathbf{x}_k$, one would predict $\mathbf{x}_i$ is preferred to $\mathbf{x}_k$. A generic classifier trained on pairs cannot make such deductions.

This problem is often addressed by introducing a latent preference function $f:\mathcal{X}\mapsto \mathbb{R}$ such that
$f(\mathbf{x}_i) > f(\mathbf{x}_j)$ whenever the user prefers item $i$ to item $j$ and $f(\mathbf{x}_i) < f(\mathbf{x}_j)$ otherwise \citep{chu2005}. This latent representation implies a pre-defined ordering of items. However, the observed data are not always consistent with a single fixed ordering, and sometimes are contradictory. Furthermore peoples' choices may be contaminated by noise, or be inaccurate because of lack of attention. To account for this randomness, the model presented by \citep{chu2005} assumes that when respondents decide between options, their preference function is contaminated by evaluation noise. The goal of inference is then to identify the latent preference function from observed pairwise comparison data.

When the evaluations of $f$ are contaminated with Gaussian noise with zero mean and (without loss of generality) variance $1/2$, we obtain the following likelihood function for the underlying preference function $f$ given the datapoint $\mathbf{x}_i$, $\mathbf{x}_j$ and corresponding label $y$:

\vspace{-0.65cm}
{\small
\begin{align}
\mathcal{P}(y|\mathbf{x}_i,\mathbf{x}_j,f) &= \Phi[(f[\mathbf{x}_i] - f[\mathbf{x}_j])y]\,,\label{eq:likelihood}
\end{align}
}

\vspace{-0.7cm}
\normalsize where $\Phi$ is the standard Gaussian cumulative distribution function. The preference learning problem can be solved by combining a GP prior on $f$ with the likelihood function in (\ref{eq:likelihood}) \cite{chu2005}. The posterior for $f$ can
then be used to make predictions on the user preferences for new pairs of items.

Note that the likelihood (\ref{eq:likelihood}) depends only on the difference between $f(\mathbf{x}_i)$ and $f(\mathbf{x}_j)$.
Let $g:\mathcal{X}^2\mapsto\mathbb{R}$ be the latent function $g(\mathbf{x}_i,\mathbf{x}_j) = f(\mathbf{x}_i) - f(\mathbf{x}_j)$.
We can recast the inference problem in terms of $g$ and ignore $f$. When the evaluation of $g$ is contaminated with standard Gaussian noise,
the likelihood for $g$ given $\mathbf{x}_i$, $\mathbf{x}_j$ and $y$ is

\vspace{-0.65cm}
{\small
{\small
\begin{align}
\mathcal{P}(y|\mathbf{x}_i,\mathbf{x}_j,g) &= \Phi[g(\mathbf{x}_i, \mathbf{x}_j)y]\,.\label{eq:likelihood2}
\end{align}
}

\vspace{-0.7cm}
\normalsize Since $g$ is obtained from $f$ through a linear operation, the GP prior on $f$ induces a GP prior on $g$.
The covariance function $k_\text{pref}$ of the GP prior on $g$ can be computed from the covariance function $k$ of the GP on $f$ as $k_\text{pref}((\x_i,\x_j),(\x_k,\x_l)) = k(\x_i,\x_k) + k(\x_j,\x_l) - k(\x_i,\x_l) - k(\x_j,\x_k)$. The derivations can be found in Section 1 of the supplementary material. We call $k_\text{pref}$ the \emph{preference kernel}. The same kernel function can be derived from a large margin classification viewpoint \cite{furnkranz2010}. However, to our knowledge, the preference kernel has not been used previously for GP-based models.	

The combination of (\ref{eq:likelihood2}) with a GP prior based on the preference kernel allows us to transform the pairwise preference learning problem into  binary classification with GPs. This means that state-of-the-art methods for GP binary classification, such as expectation propagation \cite{Minka2001}, can be applied directly to preference learning. Furthermore, the simplified likelihood (\ref{eq:likelihood2}) allows us to implement complex methods  such as the multi-user approach which is described in the following section. \subsection{Collaborative preference learning}
