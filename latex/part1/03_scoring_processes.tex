%!TEX root = ../main.tex
The scoring rule framework presented in chapter \ref{sec:scoring_rules} is already quite general and accommodates a large number of traditional and more modern estimation and scoring techniques. However, there are certain limitations as to what the framework can describe. In this chapter I extend the scoring rule framework further and consider scoring rules for general stochastic processes, in other words, scoring rules in infinite dimensional sampling spaces.

Stochastic processes have enjoyed a surge of interest from the machine learning community thanks to their use in nonparametric Bayesian inference. Nonparametric techniques based on processes like the Gaussian process, Dirichlet process, Indian buffet process have become ubiquitious in modern statistical models. It is interesting to investigate whether and how the scoring rule framework extends to these more general, infinite dimensional statistical models.

To analyse stochastic processes in the scoring rule framework I introduce a novel concept of marginal scoring rules. I show a number of examples of estimation techniques that do not fit the traditional scoring rule framework, but can be accommodated readily in this more general treatment. I will also argue that the notion of strictly proper scoring rules is insufficient when dealing with stochastic processes, and introduce an analogous property I call very strictly proper scoring. 

\section{Extensions of score matching for \iid data}

Let us recall the definition of a strictly proper scoring rule: A score $\score(x,P)$ is called strictly proper if for any two distributions $P,Q$ the following holds:

\begin{equation}
	\expect{x\sim P}S(x,P) \leq \expect{x\sim P}S(x,Q),
\end{equation}
with equality only when $P=Q$.

In this definition we are concerned with the scoring rule's behaviour in expectation under the distribution $P$. In empirical terms taking an expectation is analogous to studying the limit of the empirical mean, as we observe multiple independent copies of the distribution $x$ sampled from $P$.

Indeed, the strictly proper property of a scoring rule under suitable regularity conditions ensures that as we observe infinitely many independent and identically distributed (\iid) samples from a parametric distribution $P_{X\vert\theta}$, the parameter of the distribution can be consistently identified:

\begin{definition}[Score matching estimate]
Let $\{P_{X\vert\theta, \theta\in\Theta}\}$ be a parametric family of distributions and $\score$ a strictly proper scoring rule with respect to this class. The following estimator is called the score matching estimate:
\begin{equation}
	\hat{\theta}_N(x_1,\ldots,x_N) = \argmin_{\theta\in\Theta} \sum_{n=1}^{N}\score(x_n,P_{X\vert\theta}) \label{eqn:score_matching}
\end{equation}
The above equation is an unbiased estimating equation, and under suitable regularity conditions $\hat{\theta}_N(x_1,\ldots,x_N)$ is a consistent estimator, that is if $x_1,\ldots\sim P_{X\vert\theta_0}$\iid
\begin{equation}
	\lim_{N \rightarrow \infty} \hat{\theta}_N(x_1,\ldots,x_N) = \theta_0\hspace{1cm} P_{X\vert\theta_0}\mbox{-\,almost surely}
\end{equation}
\end{definition}

Score matching has been used to fit parametric models for decades. Maximum likelihood estimation is a typical example when the scoring rule is chosen to be the logarithmic score. In more modern work like \citep{kernelmomentmatching}, the kernel scoring rule is used to fit parametric distributions; the technique is referred to as kernel moment matching. Score matcing with the Brier and spherical scores has also been used in meteorology and epidemiology.

The score matching procedure assumes that one observes a sequence of \iid observations repeatedly sampled from the same distribution $P$. However, observed data is not always \iid. Often we want to score non-\iid sequences or sets of variables, and we would still like our parameter estimates to be consistent in some sense. Examples of such non-\iid estimation scenarios include:
\begin{enumerate}
	\item Parameter estimation in non-parametric process models, such as in Gaussian process regression, studying the limit as the size of the training data grows
	\item parameter estimation of a large Markov random field, studying constitency as the image size grows
	\item Parameter estimation in phylogenetic tree models, studying behaviour as the number of species and the size of the tree grows
	\item Bayesian model selection in hierarchical Bayesian models, where instead of \iid assumption we often find exchangeability assumptions
\end{enumerate}

In all of the examples above, we never observe a growing number of independent copies of the same random variable. Instead, we observe higher and higher dimensional marginals of the same single trajectory sampled randomly from a random process. We sample one infinitely large object from a random process once, and we study the behaviour as larger and larger parts of this object are revealed.

The above cases do not readily fit into the scoring rule framework which is specifically concerned with \iid observations from the same, fixed dimensional distribution. To analyse these cases we can extend the scoring rule framework so that we allow scoring of partial observations. Let us consider the following definition of marginal scoring rules:

\begin{definition}[Marginal scoring rule]
Let $\Xe$ be a countably infinite index set, $I\subseteq\Xe$ a subset of indices. A marginal scoring rule $R_I$ over this index set is a function that assigns a real value, $R_{I}(y_{I},\Pi)$,  to a process measure $\Pi\in\probmeasures{\Ye^{\Xe}}$ and an observed marginal $y_{I}\in\Ye^{I}$.
\end{definition}

Marginal scoring rules allow one to calculate the score of a forecast on the basis of a partial observation $y_{I}$. For example, if $\Pi$ is a distribution over images, a marginal scoring rule can assign a score to $\Pi$ even if we only observe the right-hand corner of the image, and the rest remains hidden. This definition therefore allows us to study what happens as higher and higher dimensional marginals are revealed, as we desired.

Observe, that the traditional \iid scoring rule framework can be expressed in terms of marginal scoring rules over \iid processes. Instead of thinking about repeatedly sampling from a finite dimensional distribution, we can imagine sampling one infinitely long sequence first, but then revealing longer and longer sub-sequences from it. Let $\Xe$ be the set of natural numbers, and $\Pi$ an \iid process such that $\Pi_{I}(y_{I}) = \prod_{i\in I} P(y_i)$, then we can construct marginal scoring rules as follows:

\begin{equation}
R_{I}(y_{I},\Pi) = \frac{1}{\vert I \vert} \sum_{i\in I_n} S(y_i,P)\label{eqn:decompose},
\end{equation}
where $S$ is a strictly proper scoring rule over $\Ye$.

The marginal scoring rules in eqn. \eqref{eqn:decompose} are useful in the following sense.

\begin{statement}[Consistency of marginal scoring for \iid processes]
Let us take a monotonically increasing sequence of index sets $I_1\subseteq\ldots\subseteq I_N \subseteq \ldots \subseteq \Xe$, such that $\cup_{N=1}^{\infty} I_N = \Xe$ and $\score(y,P)$ be a strictly proper scoring rule over $\Ye$ with respect to the class of marginals $P_{\theta}$. Let $\Pi_{\theta}$ denote the \iid process over $\Ye^{\Xe}$ with marginal $P_{\theta}$. Then ``typically'' the following limit holds

\begin{align}
\argmin_{\theta}R_{I_n}(y_{I_n},\Pi_{\theta^{*}}) =  \argmin_{\theta} \frac{1}{\vert I_N \vert} \sum_{i\in I_N} \score(y_i,P_{\theta}) \stackrel[N\rightarrow\infty]{P_{\theta^{*}}}{\longrightarrow} \theta^{*}
\end{align}
\end{statement}

The above equation is the same as score matching, but now we look at it slightly differently. Intuitively, consistency in this general sense means that as larger and larger marginals of a trajectory drawn from the process $\Pi_{\theta}$ are revealed, the scoring rule can identify the true parameter $\theta$ of the process from which the trajectory was drawn. When a general family of marginal scoring rules has this property, we will call it the very strictly proper property:

\begin{definition}[Very strictly proper marginal scoring]\label{thm:very_strictly_proper}
Let $R_{I}$ be a family of marginal scoring rules over processes on $\Ye^{\Xe}$, $\Qe = \{\Pi_\theta, \theta\in\Theta\}$ a family of process measures over $\Ye^{\Xe}$. $R_{I}$ is very strictly proper with respect to $\Qe$ if for any monotonically increasing sequence of index sets $I_1\subseteq\ldots\subseteq I_N \subseteq \ldots \subseteq \Xe$, such that $\cup_{N=1}^{\infty} I_N = \Xe$ the following limit holds:
\begin{align}
\lim_{N\rightarrow\infty} \argmin_{\theta} R_{I_N}(y_{I_N},\Pi_{\theta}) = \theta^{*}\hspace{1cm}\Pi_{\theta^{*}}\mbox{\,almost surely}
\end{align}
\end{definition}

In the following sections I show families of marginal scoring rules $R_I$, that do not simply decompose into sums of scoring rules on $\Ye$ for marginals $\Pi$, but most of which still have the very strictly proper property.

\subsection{Maximum product of spacings score}

The first example, \emph{maximum product of spacings (MPS) estimation} is not normally considered in the context of scoring rules, but we can now interpret it as part of this general framework of marginal scoring rules. It is an estimation technique based on the observation that if a set of points are sampled from a one dimensional uniform distribution, then the spacing between neighbouring samples should be roughly the same. Thus, a viable ``scoring rule'' for the uniform distribution measures how uneven the spacing between neighbouring samples are. The evenness of a set of numbers can be measured by the difference between arithmetic and geometric means. The above argument can be extended to arbitrary real probability distributions by noting that transforming a general non-uniform random variable by its cumulative distribution function results in a uniform random variable between $0$ and $1$.

\begin{definition}[Product of spacings score]
	Let $y_1,\ldots,y_N$ independent random variables on the real line $\Reals$. Let $P$ be a distribution over $\Reals$ with cumulative distribution function $F_{P}$. Let $\pi:\{1,\ldots,N\}\mapsto\{1,\ldots,N\}$ a rank ordering such that $n<m \implies y_{\pi_{n}}\leq y_{\pi_{m}}$. For convenience of notation let us further define $y_{\pi_0}\defeq 0$ and $y_{\pi_{N+1}}\defeq 1$.
	\begin{equation}
		R^{PS}_N(y_1,\ldots,y_N,P) = - \frac{1}{N+1} \sum_{n=0}^{N} \log \left(F_P\left(y_{\pi_{n+1}}\right) - F_P\left(y_{\pi_{n}}\right) \right)
	\end{equation}
\end{definition}

It is shown in \citep{http://fir.nes.ru/tildegkosenok/MPS.pdf} that subject to smoothness assumptions, MPS estimation, which minimises $R^{PS}_N$ is consistent when $y_n$ are sampled \iid from a distribution. That is
\begin{align}
\argmin_{\theta}R^{PS}_{N}(y_1,\ldots,y_N,\Pi_{\theta^{*}}) \stackrel[N\rightarrow\infty]{P_{\theta^{*}}}{\longrightarrow} \theta^{*}
\end{align}

Furthermore, the estimator is often statistically more efficient than maximum likelihood estimation (MLE) \citep{http://fir.nes.ru/tildegkosenok/MPS.pdf}. The drawback of the product of spacings score is that it does not readily generalise to multivariate distributions, and it requires the knowledge of the cumulative distribution function to be calculated.

\subsection{Decision theoretic scoring and $F_{\beta}$ scores}

Further examples of scores that do not decompose as in \eqref{eqn:decompose} can be constructed on decision theoretic grounds when the action and the loss that we minimise itself depends on multiple outcomes. For example in a binary case we may want to penalise imbalanced forecasters, so we prefer forecasters that produce about as many false positives as false negatives while at the same time minimise the total number of false predictions.

Most of these complicated objectives can be achieved by optimising something like the $F_{\beta}$ score, which is applied in a variety of statistical applications \citep{}:

\begin{equation}
	F_\beta = (1-\beta^2)\frac{\mbox{precision}\cdot\mbox{recall}}{\beta^2 \mbox{precision} + \mbox{recall}}
\end{equation}

The $F$ score depends on a whole sample and cannot be decomposed as a sum of terms that score each sample independently. Hence it is a good example of general marginal scoring rules.

\section{Non-\iid processes}

In the examples I gave above, the scoring rule did not decompose into a sum of univariate scores as in \eqref{eqn:decompose}, but we would still use these scores to score and estimate \iid processes. The present framework also accommodates more general cases when we want to score non-\iid processes, such as hierarchical Bayesian models, Markov random fields, processes over tree structures or Gaussian processes.

The simplest and most widely adopted scoring rule of this form is log-score (assuming marginals of $\Pi$ have densities $P_{I_n}$), which is also called (negative) evidence:

\begin{align}
	R_{I_N}(x_{I_N},\Pi) = - \frac{1}{\vert I_N \vert}\log P_{I_n}(y_{I_n}),
\end{align}

\subsection{Bayesian model selection}

The consistency of the maximum likelihood estimator has been studied with respect to particular classes of models and processes. A particularly interesting case is when the process $\Pi$ is exchangeable.

By De Finetti's theorem, exchangeable sequences of random variables have a representation as mixtures of \iid sequences, and can therefore be interpreted as hierarchical Bayesian models. Let's say we have a model $\model$, under which $y_n$ are conditionally \iid given some parameters $\theta$. Given some observed data y, the model's evidence is given by the following formula:

\begin{align}
	\mbox{evidence}(\model) &= R_{log}(y_{1:N},\Pi_{Y\vert\model})\\
		&= \log P_{Y_{1:N}\vert\model}(y_{1:N})\\
		&= \log \int \prod_{n=1}^{N} P_{Y_1\vert\theta}(y_n) P_{\theta\vert\model}(\theta) d\theta
\end{align}

We can observe that even though conditioned on $\theta$ subsequent $y_n$ variables are independent, marginally they are dependent, therefore the evidence does not decompose into a sum of terms per data-point as it would for marginally \iid models.

The evidence is accepted as a very robust criterion for Bayesian model selection and is thought to be particularly robust against over-fitting. On the other hand it is often intractable to compute exactly for complicated models, and one has to rely on various approximations such as the Bayesian information criterion (BIC)\citep{}, Akaike information criterion (AIC)\citep{}, variational lower bounds, or expectation-propagation (EP)\citep{}.

We can generalise Bayesian model selection by replacing the log-score with another family of marginal scoring rulea, such as the quadratic kernel rule from Eqn.\ \eqref{eqn:kernel_scoring}. When we use the kernel scoring rule for Bayesian model selection, it decomposes clearly into two terms, which intuitively represent the trade-off between accuracy and model flexibility.

\begin{align}
	\divergence{k}{\delta_{y}}{\Pi_{Y\vert\model}} &= \Hnorm{k(\cdot,y) - \mu_{Y\vert\model}}^2\\
		&= \Hnorm{k(\cdot,y) - \expect{\theta\sim p_{\theta\vert\model}}\mu_{Y\vert\theta}}^2\\
		&= \expect{\theta\sim p_{\theta\vert\model}} \Hnorm{k(\cdot,y) - \mu_{Y\vert\theta}}^2 - \expect{\theta\sim p_{\theta\vert\model}}\Hnorm{\mu_{X\vert \theta,\model} - \mu_{X\vert\model}}^2\\
		&= \underbrace{\expect{\theta\sim p_{\theta\vert\model}} \divergence{k}{\delta_{y}}{p_{X\vert\theta}} }_{\mbox{average accuracy}} -  \underbrace{\information{k}{X}{\theta}}_{\mbox{diversity}}
\end{align}

After \citep{} one may call this the ambiguity decomposition of the quadratic kernel score. As the Brier score is a special case of the kernel scoring rule, it naturally admits the same decomposition. The decomposition suggests that a good model is
\begin{description}
	\item[accurate:] it forecasts observed data relatively accurately on average for all parameters, and
	\item[diverse:] it is capable of expressing a diverse range of behaviours via its parameters
\end{description}

\subsection{Pseudo-likelihood}

We can also study the pseudo-likelihood score in this context. In machine learning this score may be called the leave-one-out cross-validation error.

\begin{align}
R(y_{I_N},\Pi) = - \frac{1}{\vert I_N \vert} \sum_{n\in{I_N}}\log P_{Y_n\vert Y_{I_n\backslash\{n\}}}(y_n)
\end{align}

We already noted that the pseudo-likelihood score is strictly proper, so under multiple sampling from the same size marginal, pseudo-likelihood it is typically consistent. But we can also study the limit as larger and larger marginals are considered.

The most typical application of pseudo-likelihood estimation is parameter estimation in Markov random fields. A finite graph Markov-random field is a stochastic process, where each variable is conditionally independent of the rest of the trajectory given a finite number of other variables, known as the Markov-blanket of the variable. A common example of a finite graph Markov random field is the two-dimensional square lattice Isling model \citep{Dawid's paper}. This model and its generalisations have found several applications in computer vision and image processing \citep{}.
 
Typically when studying consistency properties of pseudo-likelhiood, authors show that the pseudo-likelihood score is strictly proper and thus pseudo-likelihood estimation is consistent under repeated sampling from a finite dimensional Markov random field. In this chapter we are interested in consistency of estimation from a single draw from an infinite MRF, in the limit as larger and larger sub-graphs are observed. It turns out pseudo-likelihood estimation is consistent in this stricter sense, too \citep{GemanGraffigne}, therefore we can call it a very strictly proper scoring rule.

Pseudo-likelihood estimation can be used in other cases where computing the logarithmic score is intractable, such as estimating phylogenetic trees in models such as the infinite sites model \citep{something, something} . In this application the observed data are a set of related genomes, that are thought to have evolved from a common ancestor genome through a process of random mutations and recombinations and can therefore be related via a phylogenetic tree. The task is to infer the latent phylogenetic tree underlying the data, and to estimate model parameters such as the relative rate of mutation and recombination events.

This estimation problem is hard because of the exponential number of phylogenetic trees consistent with any one dataset. Computing the marginal likelihood (or logarithmic score, as in Eqn.\ \eqref{eqn:marginal_log_score}) is intractable as it involves computing a non-trivial sum over phylogenetic trees. However, computing the conditional distribution of just one gene (or segregating site on the DNA), conditioned on the observed values of other genes can be performed relatively efficiently in certain models, and thus pseudo-likelihood estimation may be efficiently applied to these models. It is an open question whether pseudo-likelihood estimation, or indeed maximum likelihood estimation is consistent in the limit of increasing number of alleles and species.

\subsection{Information quantities for stochastic processes}

Finally, it is a natural question to ask, whether it possible, or if at all useful to define information quantities, such as entropy and divergence, between stochastic processes. Following definition \ref{thm:very_strictly_proper} it makes sense to replace expectations with limits in these definitions.

\begin{definition}[Entropy and divergence for processes]\label{thm:process_entropy_divergence}
Let $R_{I}$ be a family of marginal scoring rules over processes on $\Ye^{\Xe}$, $R_{I}$ is very strictly proper family of marginal scoring rules.Consider a monotonically increasing sequence of index sets $I_1\subseteq\ldots\subseteq I_N \subseteq \ldots \subseteq \Xe$. Let us define the entropy or a random process $\Pi$ as follows

\begin{equation}
	\genentropy{R}{\Pi} = lim_{N\rightarrow\infty}R_{I_N}(X_{I_N},\Pi) \mbox{, where } X \sim \Pi
\end{equation}

Similarly, let us define the divergence between two processes $\Pi$ and $\Xi$ as
\begin{equation}
	\divergence{R}{\Pi}{\Xi} =  lim_{N\rightarrow\infty}R_{I_N}(X_{I_N},\Xi) - R_{I_N}(X_{I_N},\Pi) \mbox{, where } X \sim \Pi
\end{equation}
\end{definition}

In general the quantities defined above are random quantities. When the scoring rule $R$ is the logarithmic score, and $\Pi$ is a stationary stochastic process, the Shannon-McMillan-Breiman theorem ensures that the entropy defined this way converges almost surely to deterministic value \citep{}, called the source entropy of the probabilistic source $\Pi$. Under the same conditions the divergence $\divergence{R}{\Pi}{\Xi}$ also converges and is strictly positive for $\Pi \neq \Xi$.

We can conclude that in certain special cases the entropy and divergence quantities defined in definition \ref{thm:process_entropy_divergence} make sense and are useful, but very likely these generalisations are too general for practical purposes.