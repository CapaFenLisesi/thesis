%!TEX root = thesis.tex

Probability distributions and random variables play a central role in Bayesian computation. In Bayesian analysis, one models observed data by introducing latent parameters, which are treated as random variables and assigned a \emph{prior probability distribution}. The relationship between latent parameter and data is modelled via a \emph{probability distribution}, called the likelihood. The most important object of Bayesian analysis, the  \emph{posterior distribution} is obtained by combining the likelihood and prior via Bayes' rule. In the Bayesian world the posterior captures all that there is to learn about the unobserved parameter from the data.

In order to design effective Bayesian machine learning algorithms one therefore needs rich frameworks for describing, characterising, comparing and manipulating probability distributions and random variables. This thesis is centred around one such framework: strictly proper scoring rules.

Scoring rules allow us to define general notions of divergence. Divergence functionals quantify the difference or discrepancy between two probability distributions. The best known example, the Kullback-Leibler (KL)divergence, has been used for decades in a wide range of Bayesian applications. Divergences play a central role in approximate inference.

Scoring rules also provide ways to quantify the value of information one random quantity provides about another one. The value of information functionals that one can define based on the framework, generalise the widely used Shannon's mutual information. Quantifying the value of information is of central importance in active machine learning and optimal experiment design, where one seeks to select the most informative measurements to perform. The generalisations considered in this thesis allows one to contextualise the value of information and unify a wide range of recent and old work on Bayesian experiment design.

Part \ref{part:1} is a general discussion of proper scoring rules, measures of divergence and information. Chapter \ref{sec:scoring_rules} introduces key concepts: proper and strictly proper scoring rules, Bregman divergences and the value of information. I give a thorough review of the most common scoring rules used in statistics and machine learning. In addition, I show that maximum mean discrepancy, a kernel-based divergence measure is also related to scoring rules and introduce a novel scoring rule called the spherical kernel score.

Part \ref{part:2} discusses the application of proper divergences in approximate Bayesian inference. Approximate inference methods make it possible to infer probabilistic models from data when exact Bayesian inference is computationally intractable. Chapter \ref{sec:approximate_inference} outlines a general framework for approximate inference using scoring rule-based divergences. The framework is derived from Bayesian decision theory, and is called loss-calibrated approximate inference. I discuss opportunities, limitations, and point out the connections to existing methodology. I also give a blueprint for a class of non-parametric approximate inference algorithms called loss-calibrated quasi-Monte Carlo.

In Chapter \ref{sec:herding} I study two practical examples of quasi-Monte Carlo algorithms, kernel herding and Bayesian quadrature. I show that both algorithms seek to minimise maximum mean discrepancy, hence they are special cases of loss-calibrated quasi-Monte Carlo. 

Part \ref{part:3} focuses on measures of information and their application to Bayesian active learning. Active learning is a form of machine learning in which a learning algorithm is able to interactively query the environment in order to build a statistical model more quickly. In Chapter \ref{sec:active_learning_framework} a general framework for Bayesian active learning is described, based on proper scoring rules and associated information quantities. The chapter is also a unifying review of several practical machine learning algorithms that are reinterpreted and generalised in this context.

Chapter \ref{sec:BALD} introduces Bayesian Active Learning by Disagreement (BALD), a computationally convenient approach to Bayesian experiment design. The method exploits the symmetry of Shannon's mutual information and reformulates information theoretic active learning so that it requires substantially lighter computations. I demonstrate experimentally that the algorithm achieves state-of-the-art performance in active binary classification and pairwise preference elicitation using Gaussian process priors.

In Chapter \ref{sec:quantum} BALD is applied to quantum state tomography, a statistical inference problem frequently incurred in experimental quantum physics. Combined with fast sequential importance sampling, BALD outperforms state-of-the-art solutions such as mutually unbiased bases by orders of magnitude. The algorithm has appealing potential applications in experimental physics and has been validated experimentally in a real experiment.